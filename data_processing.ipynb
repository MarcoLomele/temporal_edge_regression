{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Italy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding header entry\n",
    "file_path_cases = 'data/Italy/italy_labels.csv'\n",
    "\n",
    "with open(file_path_cases, 'r') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "if content[0][0:5] != 'index':\n",
    "    content[0] = 'index' + content[0]\n",
    "\n",
    "with open(file_path_cases, 'w') as f:\n",
    "    f.writelines(content)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning columns\n",
    "cases_ita_df = pd.read_csv(file_path_cases)\n",
    "cases_ita_df = cases_ita_df.drop(columns=['index', 'id'])\n",
    "cases_ita_df = cases_ita_df.iloc[:, :80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix Bergamo outlier at 2020-05-12 with average of week\n",
    "cases_ita_df.at[12, '2020-05-12'] = int(cases_ita_df.iloc[12, 72:79].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting subset of cities by percentile.\n",
    "#upper_quant_ita = cases_ita_df.iloc[:, 1:].max(axis=1).quantile(0.75)\n",
    "#cases_ita_df = cases_ita_df[cases_ita_df.iloc[:, 1:].ge(upper_quant_ita).any(axis=1)]\n",
    "\n",
    "#Selecting subset of cities by number of absoluet cases.\n",
    "top_30_ita = cases_ita_df.iloc[:, 1:].sum(axis=1).sort_values(ascending=False).head(30).index\n",
    "cases_ita_df = cases_ita_df.loc[top_30_ita]\n",
    "selected_cities_ita = cases_ita_df['name'].to_numpy(dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing CSV\n",
    "cases_spa_df = pd.read_csv('data/Spain/spain_labels.csv')\n",
    "cases_spa_df[cases_spa_df.columns[1:]] = cases_spa_df.iloc[:, 1:].astype('int64')\n",
    "\n",
    "#Outlier due to mis-reporting\n",
    "cases_spa_df = cases_spa_df.drop(index = 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting subset of cities by quantile\n",
    "#upper_quant_spa = cases_spa_df.iloc[:, 1:].mean(axis=1).quantile(0.80)\n",
    "#cases_spa_df = cases_spa_df[cases_spa_df.iloc[:, 1:].ge(upper_quant_spa).any(axis=1)]\n",
    "\n",
    "#Selecting subset by absolute number of cases.\n",
    "top_30_spa = cases_spa_df.iloc[:, 1:].sum(axis=1).sort_values(ascending=False).head(30).index\n",
    "cases_spa_df = cases_spa_df.loc[top_30_spa]\n",
    "selected_cities_spa = cases_spa_df['name'].to_numpy(dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing CSV\n",
    "cases_fra_df = pd.read_csv('data/France/france_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting subset of cities by quantiles\n",
    "#upper_quant_fra = cases_fra_df.iloc[:, 1:].mean(axis=1).quantile(0.8)\n",
    "#cases_fra_df = cases_fra_df[cases_fra_df.iloc[:, 1:].ge(upper_quant_fra).any(axis=1)]\n",
    "\n",
    "#Selecting cities by absolute number of cases\n",
    "top_30_fra = cases_fra_df.iloc[:, 1:].sum(axis=1).sort_values(ascending=False).head(30).index\n",
    "cases_fra_df = cases_fra_df.loc[top_30_fra]\n",
    "selected_cities_fra = cases_fra_df['name'].to_numpy(dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## England"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_eng_df = pd.read_csv('data/England/england_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting cities by quantiles\n",
    "#upper_quant_eng = cases_eng_df.iloc[:, 1:].mean(axis=1).quantile(0.75)\n",
    "#cases_eng_df = cases_eng_df[cases_eng_df.iloc[:, 1:].ge(upper_quant_eng).any(axis=1)]\n",
    "\n",
    "#Selecting subset of cities by absolute value\n",
    "top_30_eng = cases_eng_df.iloc[:, 1:].sum(axis=1).sort_values(ascending=True).head(30).index\n",
    "cases_eng_df = cases_eng_df.loc[top_30_eng]\n",
    "selected_cities_eng = cases_eng_df['name'].to_numpy(dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cities_list = [selected_cities_ita, selected_cities_spa, selected_cities_fra, selected_cities_eng]\n",
    "cases_dfs_list = [cases_ita_df, cases_spa_df, cases_fra_df, cases_eng_df]\n",
    "countries = ['ita', 'spa', 'fra', 'eng']\n",
    "folder_path_dict = {\n",
    "    'ita' : 'data/Italy/graphs',\n",
    "    'spa' : 'data/Spain/graphs',\n",
    "    'fra' : 'data/France/graphs',\n",
    "    'eng' : 'data/England/graphs',\n",
    "}\n",
    "movement_dfs_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/y1r4j5314tj34x7tn5g1cdg80000gn/T/ipykernel_81014/1267743914.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  movement_df = pd.concat([movement_df, df], axis = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/y1r4j5314tj34x7tn5g1cdg80000gn/T/ipykernel_81014/1267743914.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  movement_df = pd.concat([movement_df, df], axis = 0)\n",
      "/var/folders/7g/y1r4j5314tj34x7tn5g1cdg80000gn/T/ipykernel_81014/1267743914.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  movement_df = pd.concat([movement_df, df], axis = 0)\n",
      "/var/folders/7g/y1r4j5314tj34x7tn5g1cdg80000gn/T/ipykernel_81014/1267743914.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  movement_df = pd.concat([movement_df, df], axis = 0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(countries)):\n",
    "    movement_df = pd.DataFrame(columns=['src', 'trg', 'movement', 'date'])\n",
    "    movement_df = movement_df.astype({'src':'str', 'trg':'str', 'movement':'int64'})\n",
    "    movement_df['date'] = pd.to_datetime(movement_df['date'])\n",
    "\n",
    "    folder_path = folder_path_dict[countries[i]]\n",
    "\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.readlines()\n",
    "\n",
    "        if content[0].strip() != ','.join(['src', 'trg', 'movement']):\n",
    "            content.insert(0, ','.join(['src', 'trg', 'movement']) + '\\n')\n",
    "        \n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(content)\n",
    "            f.close()\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.astype({'src':'str', 'trg':'str', 'movement':'int64'})\n",
    "        df = df[(df['src'].isin(selected_cities_list[i])) & (df['trg'].isin(selected_cities_list[i]))]\n",
    "\n",
    "        year, month, day = int(filename[3:-10]), int(filename[8:-7]), int(filename[11:-4])\n",
    "        date = datetime(year, month, day)\n",
    "        df['date'] = date   \n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "        df = df.sort_values(by=['src', 'trg'])\n",
    "\n",
    "        movement_df = pd.concat([movement_df, df], axis = 0)\n",
    "\n",
    "    movement_df = movement_df.reset_index(drop=True)\n",
    "    movement_dfs_list.append(movement_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_ita_df = movement_dfs_list[0]\n",
    "movement_spa_df = movement_dfs_list[1]\n",
    "movement_fra_df = movement_dfs_list[2]\n",
    "movement_eng_df = movement_dfs_list[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cities_ita = np.sort(selected_cities_ita)\n",
    "selected_cities_spa = np.sort(selected_cities_spa)\n",
    "selected_cities_fra = np.sort(selected_cities_fra)\n",
    "selected_cities_eng = np.sort(selected_cities_eng)\n",
    "\n",
    "mapping_ita = {city: i for i, city in enumerate(selected_cities_ita, start=1)}\n",
    "mapping_spa = {city: i for i, city in enumerate(selected_cities_spa, start=1)}\n",
    "mapping_fra = {city: i for i, city in enumerate(selected_cities_fra, start=1)}\n",
    "mapping_eng = {city: i for i, city in enumerate(selected_cities_eng, start=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_ita_df['src'] = movement_ita_df['src'].map(mapping_ita)\n",
    "movement_ita_df['trg'] = movement_ita_df['trg'].map(mapping_ita)\n",
    "cases_ita_df['name'] = cases_ita_df['name'].map(mapping_ita)\n",
    "cases_ita_df = cases_ita_df.sort_values(by=['name'])\n",
    "cases_ita_df = cases_ita_df.reset_index(drop=True)\n",
    "\n",
    "movement_spa_df['src'] = movement_spa_df['src'].map(mapping_spa)\n",
    "movement_spa_df['trg'] = movement_spa_df['trg'].map(mapping_spa)\n",
    "cases_spa_df['name'] = cases_spa_df['name'].map(mapping_spa)\n",
    "cases_spa_df = cases_spa_df.sort_values(by=['name'])\n",
    "cases_spa_df = cases_spa_df.reset_index(drop=True)\n",
    "\n",
    "movement_fra_df['src'] = movement_fra_df['src'].map(mapping_fra)\n",
    "movement_fra_df['trg'] = movement_fra_df['trg'].map(mapping_fra)\n",
    "cases_fra_df['name'] = cases_fra_df['name'].map(mapping_fra)\n",
    "cases_fra_df = cases_fra_df.sort_values(by=['name'])\n",
    "cases_fra_df = cases_fra_df.reset_index(drop=True)\n",
    "\n",
    "movement_eng_df['src'] = movement_eng_df['src'].map(mapping_eng)\n",
    "movement_eng_df['trg'] = movement_eng_df['trg'].map(mapping_eng)\n",
    "cases_eng_df['name'] = cases_eng_df['name'].map(mapping_eng)\n",
    "cases_eng_df = cases_eng_df.sort_values(by=['name'])\n",
    "cases_eng_df = cases_eng_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movement-Cases Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_movement_ita_df = movement_ita_df.groupby(['trg', 'date'])['movement'].sum().reset_index()\n",
    "in_movement_ita_df = in_movement_ita_df.rename(columns={'trg':'city'})\n",
    "out_movement_ita_df = movement_ita_df.groupby(['src', 'date'])['movement'].sum().reset_index()\n",
    "out_movement_ita_df = out_movement_ita_df.rename(columns={'src':'city'})\n",
    "\n",
    "in_movement_spa_df = movement_spa_df.groupby(['trg', 'date'])['movement'].sum().reset_index()\n",
    "in_movement_spa_df = in_movement_spa_df.rename(columns={'trg':'city'})\n",
    "out_movement_spa_df = movement_spa_df.groupby(['src', 'date'])['movement'].sum().reset_index()\n",
    "out_movement_spa_df = out_movement_spa_df.rename(columns={'src':'city'})\n",
    "\n",
    "in_movement_fra_df = movement_fra_df.groupby(['trg', 'date'])['movement'].sum().reset_index()\n",
    "in_movement_fra_df = in_movement_fra_df.rename(columns={'trg':'city'})\n",
    "out_movement_fra_df = movement_fra_df.groupby(['src', 'date'])['movement'].sum().reset_index()\n",
    "out_movement_fra_df = out_movement_fra_df.rename(columns={'src':'city'})\n",
    "\n",
    "in_movement_eng_df = movement_eng_df.groupby(['trg', 'date'])['movement'].sum().reset_index()\n",
    "in_movement_eng_df = in_movement_eng_df.rename(columns={'trg':'city'})\n",
    "out_movement_eng_df = movement_eng_df.groupby(['src', 'date'])['movement'].sum().reset_index()\n",
    "out_movement_eng_df = out_movement_eng_df.rename(columns={'src':'city'})\n",
    "\n",
    "net_movement_ita_df = in_movement_ita_df.merge(out_movement_ita_df, on=['city', 'date'], suffixes=['_inward', '_outward'])\n",
    "net_movement_ita_df['movement_net_lag_0'] = net_movement_ita_df['movement_inward'] - net_movement_ita_df['movement_outward']\n",
    "net_movement_ita_df = net_movement_ita_df.drop(columns=['movement_inward', 'movement_outward'])\n",
    "\n",
    "net_movement_spa_df = in_movement_spa_df.merge(out_movement_spa_df, on=['city', 'date'], suffixes=['_inward', '_outward'])\n",
    "net_movement_spa_df['movement_net_lag_0'] = net_movement_spa_df['movement_inward'] - net_movement_spa_df['movement_outward']\n",
    "net_movement_spa_df = net_movement_spa_df.drop(columns=['movement_inward', 'movement_outward'])\n",
    "\n",
    "net_movement_fra_df = in_movement_fra_df.merge(out_movement_fra_df, on=['city', 'date'], suffixes=['_inward', '_outward'])\n",
    "net_movement_fra_df['movement_net_lag_0'] = net_movement_fra_df['movement_inward'] - net_movement_fra_df['movement_outward']\n",
    "net_movement_fra_df = net_movement_fra_df.drop(columns=['movement_inward', 'movement_outward'])\n",
    "\n",
    "net_movement_eng_df = in_movement_eng_df.merge(out_movement_eng_df, on=['city', 'date'], suffixes=['_inward', '_outward'])\n",
    "net_movement_eng_df['movement_net_lag_0'] = net_movement_eng_df['movement_inward'] - net_movement_eng_df['movement_outward']\n",
    "net_movement_eng_df = net_movement_eng_df.drop(columns=['movement_inward', 'movement_outward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_movement_ita_df = in_movement_ita_df.rename(columns={'movement':'movement_net_lag_0'})\n",
    "out_movement_ita_df = out_movement_ita_df.rename(columns={'movement':'movement_net_lag_0'})\n",
    "\n",
    "in_movement_spa_df = in_movement_spa_df.rename(columns={'movement':'movement_net_lag_0'})\n",
    "out_movement_spa_df = out_movement_spa_df.rename(columns={'movement':'movement_net_lag_0'})\n",
    "\n",
    "in_movement_fra_df = in_movement_fra_df.rename(columns={'movement':'movement_net_lag_0'})\n",
    "out_movement_fra_df = out_movement_fra_df.rename(columns={'movement':'movement_net_lag_0'})\n",
    "\n",
    "in_movement_eng_df = in_movement_eng_df.rename(columns={'movement':'movement_net_lag_0'})\n",
    "out_movement_eng_df = out_movement_eng_df.rename(columns={'movement':'movement_net_lag_0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALWAYS IN THIS ORDER: Ita, Spa, Fra, Eng\n",
    "mov_dfs_list = [out_movement_ita_df, out_movement_spa_df, out_movement_fra_df, out_movement_eng_df]\n",
    "\n",
    "#Lagging\n",
    "for df in mov_dfs_list:\n",
    "    for i in range(15):\n",
    "        df[f'movement_net_lag_{i}'] = df.groupby('city')['movement_net_lag_0'].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/Library/CloudStorage/Dropbox/University/Bachelor/Year 3/Bocconi (2)/Thesis (GNNs Lomele)/Experiment/temporal_edge_regression/.venv/lib/python3.11/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/marco/Library/CloudStorage/Dropbox/University/Bachelor/Year 3/Bocconi (2)/Thesis (GNNs Lomele)/Experiment/temporal_edge_regression/.venv/lib/python3.11/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "cities = range(1, 31)\n",
    "lags = range(15)\n",
    "countries = [0, 1, 2, 3]\n",
    "\n",
    "corrs_dfs = []\n",
    "\n",
    "for country in countries:\n",
    "    movement_df = mov_dfs_list[country]\n",
    "    cases_df = cases_dfs_list[country]\n",
    "    \n",
    "    corrs_df = pd.DataFrame(index=cities, columns=[f'lag_{lag}' for lag in lags])\n",
    "    \n",
    "    for city in cities:\n",
    "        movement_city = movement_df[movement_df['city'] == city]\n",
    "        case_city = cases_df[cases_df['name'] == city].iloc[0, 1:]  # Skip the 'name' column\n",
    "        \n",
    "        for lag in lags:\n",
    "            lagged_mov_vals = movement_city[f'movement_net_lag_{lag}'].values\n",
    "            mask = ~np.isnan(lagged_mov_vals)\n",
    "            lagged_mov_vals = lagged_mov_vals[mask]\n",
    "            \n",
    "            # Fix lenghts\n",
    "            min_length = min(len(lagged_mov_vals), len(case_city))\n",
    "            case_city_lagged = case_city.values[len(case_city)-min_length:]\n",
    "            \n",
    "            correlation = pd.Series(lagged_mov_vals).corr(pd.Series(case_city_lagged))\n",
    "            corrs_df.at[city, f'lag_{lag}'] = correlation\n",
    "    \n",
    "    corrs_dfs.append(corrs_df)\n",
    "\n",
    "corrs_ita_df = corrs_dfs[0]\n",
    "corrs_spa_df = corrs_dfs[1]\n",
    "corrs_fra_df = corrs_dfs[2]\n",
    "corrs_eng_df = corrs_dfs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_corr_ita_df = pd.DataFrame(index=corrs_ita_df.index, columns=['best_lag', 'corr_value', 'second_best_lag','second_best_corr_value'])\n",
    "max_corr_spa_df = pd.DataFrame(index=corrs_spa_df.index, columns=['best_lag', 'corr_value', 'second_best_lag','second_best_corr_value'])\n",
    "max_corr_fra_df = pd.DataFrame(index=corrs_fra_df.index, columns=['best_lag', 'corr_value', 'second_best_lag','second_best_corr_value'])\n",
    "max_corr_eng_df = pd.DataFrame(index=corrs_eng_df.index, columns=['best_lag', 'corr_value', 'second_best_lag','second_best_corr_value'])\n",
    "\n",
    "max_corr_dfs_list = [max_corr_ita_df, max_corr_spa_df, max_corr_fra_df, max_corr_eng_df]\n",
    "corrs_dfs_list = [corrs_ita_df, corrs_spa_df, corrs_fra_df, corrs_eng_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country_idx in range(4):\n",
    "    corrs_df = corrs_dfs_list[country_idx]\n",
    "    max_corr = max_corr_dfs_list[country_idx]\n",
    "    \n",
    "    for city in corrs_df.index:\n",
    "        value = corrs_df.loc[city].abs()\n",
    "\n",
    "        top_values = value.sort_values(ascending=False).head(2)\n",
    "        best_lag = top_values.index[0] if len(top_values) > 0 else None\n",
    "        best_value = top_values.iloc[0] if len(top_values) > 0 else None\n",
    "        second_best_lag = top_values.index[1] if len(top_values) > 1 else None\n",
    "        second_best_value = top_values.iloc[1] if len(top_values) > 1 else None\n",
    "        \n",
    "        max_corr.at[city, 'best_lag'] = best_lag\n",
    "        max_corr.at[city, 'corr_value'] = best_value\n",
    "        max_corr.at[city, 'second_best_lag'] = second_best_lag\n",
    "        max_corr.at[city, 'second_best_corr_value'] = second_best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "best_lag\n",
       "lag_5     4\n",
       "lag_14    3\n",
       "lag_12    3\n",
       "lag_10    3\n",
       "lag_0     3\n",
       "lag_9     3\n",
       "lag_1     3\n",
       "lag_11    2\n",
       "lag_7     1\n",
       "lag_3     1\n",
       "lag_6     1\n",
       "lag_13    1\n",
       "lag_2     1\n",
       "lag_4     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_corr_spa_df['best_lag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up:\n",
    "\n",
    "1. Find optimal lag of movement data. Comapare correlation between number of covid cases today and movemement data lagged by 1 to 14 days. \n",
    "2. Implications of using directed vs undirected edges. \n",
    "3. Exploration of using features on the node that provide more information about COVID transmission: density of population, number of cities/towns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
